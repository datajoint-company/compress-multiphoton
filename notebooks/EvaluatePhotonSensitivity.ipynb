{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe4d98e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pynwb import NWBHDF5IO\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from dandi.dandiapi import DandiAPIClient\n",
    "from compress_multiphoton import compute_sensitivity\n",
    "from fsspec.implementations.cached import CachingFileSystem\n",
    "import pathlib\n",
    "import fsspec\n",
    "import pynwb\n",
    "import h5py\n",
    "import colorcet as cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a6f31dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_figure(scan, figure_filename, title=None):\n",
    "    qs = compute_sensitivity(scan.transpose(1,2,0))\n",
    "    print('Quantal size: {sensitivity}\\nIntercept: {zero_level}\\n'.format(**qs))\n",
    "    \n",
    "    fig, axx = plt.subplots(2,2, figsize=(9, 7))\n",
    "    q = qs['sensitivity']\n",
    "    b = qs['zero_level']\n",
    "    axx = iter(axx.flatten())\n",
    "\n",
    "    ax = next(axx)\n",
    "    m = scan.mean(axis=0)\n",
    "    _ = ax.imshow(m, vmin=0, vmax=np.quantile(m, 0.999), cmap='gray')\n",
    "    ax.axis(False)\n",
    "    ax.set_title('average')\n",
    "\n",
    "    ax = next(axx)\n",
    "    v = ((scan[1:,:,:].astype('float64') - scan[:-1,:,:]) ** 2/2).mean(axis=0)\n",
    "    imx = np.stack(((m-b)/q, v/q/q, (m-b)/q), axis=-1)\n",
    "    _ = ax.imshow(np.minimum(1, np.sqrt(0.01 + np.maximum(0, imx/np.quantile(imx, 0.9999))) - 0.1), cmap='PiYG')\n",
    "    cbar = plt.colorbar(_, ax=ax, ticks=[0.05, .5, 0.95])\n",
    "    cbar.ax.set_yticklabels(['<< 1', '1', '>> 1'])  \n",
    "    ax.axis(False)\n",
    "    ax.set_title('coefficient of variation')\n",
    "\n",
    "    ax = next(axx)\n",
    "    x = np.arange(qs[\"min_intensity\"], qs[\"max_intensity\"])\n",
    "    fit = qs[\"model\"].predict(x.reshape(-1, 1))\n",
    "    ax.scatter(x, np.minimum(fit[-1]*2, qs[\"variance\"]), s=2, alpha=0.5)\n",
    "    ax.plot(x, fit, 'r')\n",
    "    ax.grid(True)\n",
    "    ax.set\n",
    "    ax.set_xlabel('intensity')\n",
    "    ax.set_ylabel('variance')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "\n",
    "    ax = next(axx)\n",
    "    im = (scan.mean(axis=0)-qs['zero_level'])/qs['sensitivity']\n",
    "    mx = np.quantile(im, 0.999)\n",
    "    _ = ax.imshow(im, vmin=-mx, vmax=mx, cmap=cc.cm.CET_D13)\n",
    "    plt.colorbar(_, ax=ax)\n",
    "    ax.axis(False)\n",
    "    ax.set_title('Quantum flux\\nphotons / pixel / frame');\n",
    "\n",
    "    plt.suptitle(f'{title or figure_filename}\\nPhoton sensitivity: {qs[\"sensitivity\"]:4.1f}')\n",
    "    fig.savefig(figure_filename, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "662e06ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all paths for microns dataset latest published version\n",
    "dandiset_id = \"000402\"   # MICRONS\n",
    "dandiset_id = \"000037\"   # OpenScope\n",
    "\n",
    "with DandiAPIClient() as client:\n",
    "    assets = client.get_dandiset(dandiset_id).get_assets()\n",
    "    s3_urls = [x.get_content_url(follow_redirects=1, strip_query=True) for x in assets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3704be06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a caching scheme for DANDI downloads\n",
    "cache_path = pathlib.Path('./cache');\n",
    "cache_path.mkdir(parents=True, exist_ok=True)\n",
    "fs = CachingFileSystem(fs=fsspec.filesystem(\"http\"), cache_storage=str(cache_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da287ba5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dimitri/opt/miniconda3/envs/benv/lib/python3.10/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.5.1 because version 1.7.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/Users/dimitri/opt/miniconda3/envs/benv/lib/python3.10/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'core' version 2.5.0 because version 2.6.0-alpha is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/Users/dimitri/opt/miniconda3/envs/benv/lib/python3.10/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.2.0 because version 0.4.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n"
     ]
    }
   ],
   "source": [
    "# make figures for file collections on DANDI\n",
    "figure_path = pathlib.Path('./figures') / f\"dandi-{dandiset_id}\"\n",
    "figure_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for url in s3_urls:\n",
    "    # open the file\n",
    "    with fs.open(url, \"rb\") as f:\n",
    "        with h5py.File(f) as file:\n",
    "            with pynwb.NWBHDF5IO(file=file, load_namespaces=True) as io:\n",
    "\n",
    "                # get all two-photon series objects\n",
    "                collection = (  \n",
    "                    _ for _ in io.read().objects.values() \n",
    "                    if isinstance(_, pynwb.ophys.TwoPhotonSeries))\n",
    "\n",
    "                for count, two_photon_series in enumerate(collection):\n",
    "                    \n",
    "                    if count <= 4:\n",
    "                        continue\n",
    "\n",
    "                    # dx, dy = two_photon_series.imaging_plane.grid_spacing[:]\n",
    "                    # timestamps = two_photon_series.timestamps[:]\n",
    "                    # for some datasets, might have to use two_photon_series.rate\n",
    "\n",
    "                    scan = two_photon_series.data[250:750]\n",
    "                    print('::-::')\n",
    "\n",
    "                    try:\n",
    "                        make_figure(scan, figure_path / f\"{url.split('/')[-1]}-{count:03}.png\", \n",
    "                                title=f\"NWB-id:{two_photon_series.get_ancestor().identifier}\\n{two_photon_series.get_ancestor().session_id}\")\n",
    "                    except Exception as e:\n",
    "                        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5e91a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benv",
   "language": "python",
   "name": "benv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
